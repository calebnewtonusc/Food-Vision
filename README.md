# Food Vision

**Production-Ready Food101 Image Classifier with Full-Stack Deployment**

A complete ML engineering project demonstrating end-to-end workflow: data preparation, training, rigorous evaluation, and production deployment. Uses EfficientNetB2 on a 3-class subset of Food101 (pizza, steak, sushi) with FastAPI backend and React frontend deployed to foodvis.in.

## What It Does

- **Classifies food images** into 3 categories with confidence scores
- **Trains with reproducibility** - Locked seeds, versioned datasets, documented configs
- **Evaluates rigorously** - Metrics, confusion matrix, calibration, latency profiling
- **Deploys to production** - FastAPI backend on HF Spaces, React frontend on Vercel
- **Custom domain** - Live at https://foodvis.in
- **Documents honestly** - Failure modes, limitations, and clear evaluation results

## Live Demo

**ðŸš€ Try it now:** [https://foodvis.in](https://foodvis.in)

## Core Results

| Metric | Baseline | Improved | Target |
|--------|----------|----------|--------|
| **Accuracy** | 94.27% âœ… | **97.20%** âœ… | >90% |
| **F1 Score** | N/A | **0.9720** âœ… | >0.90 |
| **ECE (Calibration)** | N/A | **0.0147** âœ… | <0.05 |
| **Model Size** | 30MB | 55MB | <50MB* |

*Improved model is 55MB due to unfrozen layers (still deployable)

## Tech Stack

**Training & Evaluation:**
- PyTorch 2.1.0 + torchvision 0.16.0
- EfficientNetB2 (pretrained on ImageNet)
- Custom EvalHarness for comprehensive evaluation
- scikit-learn, matplotlib, seaborn

**Backend:**
- FastAPI 0.104.1
- Hugging Face Spaces (Docker deployment)
- CPU inference (~106ms per image, ~3.3s for batched predictions)

**Frontend:**
- React 18.2.0
- Tailwind CSS (via CDN)
- Vercel deployment
- Custom domain (foodvis.in)

## Project Structure

```
FoodVision/
â”œâ”€â”€ src/                   # Core training code
â”‚   â”œâ”€â”€ train.py           # Main training script with early stopping
â”‚   â”œâ”€â”€ models.py          # EfficientNetB2 model with gradual unfreezing
â”‚   â”œâ”€â”€ data.py            # Dataset, transforms, data loaders
â”‚   â”œâ”€â”€ config.py          # YAML config loader
â”‚   â””â”€â”€ utils.py           # Helper functions
â”œâ”€â”€ evalharness/           # Comprehensive evaluation library
â”‚   â”œâ”€â”€ metrics/           # Classification metrics (accuracy, F1, precision/recall)
â”‚   â”œâ”€â”€ confusion/         # Confusion matrix analysis
â”‚   â”œâ”€â”€ calibration/       # Calibration analysis (ECE, reliability diagrams)
â”‚   â”œâ”€â”€ perf/              # Latency profiling (p50/p95/p99)
â”‚   â””â”€â”€ report/            # Report generation
â”œâ”€â”€ scripts/               # Utility scripts
â”‚   â”œâ”€â”€ download_data.py   # Download Food101 subset
â”‚   â””â”€â”€ evaluate.py        # Run full evaluation
â”œâ”€â”€ configs/               # Training configurations
â”‚   â”œâ”€â”€ baseline.yaml      # Frozen backbone config
â”‚   â””â”€â”€ improved.yaml      # Fine-tuning config with discriminative LR
â”œâ”€â”€ backend/               # FastAPI inference server
â”‚   â”œâ”€â”€ app.py             # FastAPI application
â”‚   â”œâ”€â”€ model.py           # Model loading and inference
â”‚   â”œâ”€â”€ requirements.txt   # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile         # Docker config for HF Spaces
â”‚   â””â”€â”€ README.md          # API documentation
â”œâ”€â”€ frontend/              # React web application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js         # Main app component
â”‚   â”‚   â””â”€â”€ components/    # UI components
â”‚   â”œâ”€â”€ public/            # Static assets
â”‚   â”œâ”€â”€ package.json       # npm dependencies
â”‚   â””â”€â”€ vercel.json        # Vercel deployment config
â”œâ”€â”€ artifacts/             # Training outputs (gitignored)
â”‚   â”œâ”€â”€ baseline/          # Baseline model results
â”‚   â””â”€â”€ improved/          # Improved model results
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Original Food101 (~5GB)
â”‚   â””â”€â”€ processed/         # 3-class subset (train/test splits)
â”œâ”€â”€ DEPLOYMENT.md          # Complete deployment guide
â””â”€â”€ README.md              # This file
```

## Getting Started

### Prerequisites

- Python 3.11+
- 8GB RAM minimum
- 10GB disk space (for dataset)
- CUDA GPU optional (CPU works fine)

### Quick Start (Training & Evaluation)

```bash
# 1. Clone repository (or cd to project directory)
cd FoodVision

# 2. Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install dependencies
pip install torch==2.1.0 torchvision==0.16.0
pip install -r requirements.txt

# 4. Download Food101 dataset (~5GB, takes 5-10 minutes)
python scripts/download_data.py

# 5. Train baseline model (frozen backbone, 10 epochs)
python src/train.py --config configs/baseline.yaml

# 6. Train improved model (fine-tuning, 15 epochs)
python src/train.py --config configs/improved.yaml

# 7. Evaluate improved model
python scripts/evaluate.py \
  --model artifacts/improved/best_model.pth \
  --data-dir data/processed

# 8. View results
open artifacts/improved/evaluation_summary.json
open artifacts/improved/confusion_matrix.png
open artifacts/improved/reliability_diagram.png
```

### Quick Start (Local API Testing)

```bash
# 1. Copy trained model to backend
cp artifacts/improved/best_model.pth backend/models/

# 2. Start FastAPI server
cd backend/
pip install -r requirements.txt
python app.py

# 3. Test API (in another terminal)
curl http://localhost:8000/health
curl -X POST -F "file=@test_image.jpg" http://localhost:8000/predict

# 4. View API docs
open http://localhost:8000/docs
```

### Quick Start (Frontend Development)

```bash
# 1. Install frontend dependencies
cd frontend/
npm install

# 2. Start development server
npm start

# 3. Open browser
# Visit http://localhost:3000

# 4. Build for production
npm run build
```

## Training Pipeline

### Baseline Model
- **Architecture:** EfficientNetB2 (pretrained on ImageNet)
- **Strategy:** Freeze entire backbone, train only classifier head
- **Classifier:** Dropout(0.3) + Linear(1408 â†’ 3)
- **Training:** 10 epochs, batch size 32
- **Optimizer:** Adam (LR=1e-3, weight decay=1e-4)
- **Loss:** Cross-entropy
- **Augmentation:** Basic (resize, center crop, normalize)
- **Target:** 88-92% accuracy

### Improved Model (Progressive Fine-Tuning)
- **Strategy:** Unfreeze last 2 blocks of EfficientNetB2
- **Discriminative Learning Rates:**
  - Frozen layers: 0
  - Mid layers (blocks 0-5): 1e-5
  - Last blocks (blocks 6-7): 1e-4
  - Classifier head: 1e-3
- **Training:** 15 epochs, cosine annealing scheduler
- **Augmentation:** Enhanced (random crops, flips, color jitter, rotation)
- **Target:** 92-95% accuracy
- **Why impressive:** Shows transfer learning best practices, not brute force

### Reproducibility Guarantees
- Deterministic seeds (Python=42, NumPy=42, PyTorch=42)
- torch.backends.cudnn.deterministic = True
- Dataset SHA-256 checksums
- Locked class order (pizza=0, steak=1, sushi=2)
- Config YAML saved with every run
- Git commit hash captured
- Training history logged (train/test loss & accuracy per epoch)

## Evaluation with EvalHarness

Every run produces a comprehensive evaluation report:

### Metrics
- Accuracy (overall and per-class)
- F1 (macro and per-class)
- Confusion matrix with top confusions

### Calibration
- Confidence histogram
- Expected Calibration Error (ECE)
- Overconfident examples (high confidence, wrong prediction)

### Performance
- Model size (MB)
- Parameter count
- Inference latency (p50, p95) on CPU

## Production Deployment

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        foodvis.in                   â”‚
â”‚    (Vercel - React Frontend)        â”‚
â”‚  â€¢ Drag-and-drop upload             â”‚
â”‚  â€¢ Real-time predictions            â”‚
â”‚  â€¢ Confidence visualization         â”‚
â”‚  â€¢ Demo gallery                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ HTTPS/CORS
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Hugging Face Spaces            â”‚
â”‚      (FastAPI Backend)              â”‚
â”‚  â€¢ /predict endpoint                â”‚
â”‚  â€¢ Model inference (CPU)            â”‚
â”‚  â€¢ <100ms latency                   â”‚
â”‚  â€¢ Automatic scaling                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Backend (FastAPI + HF Spaces)
- **Framework:** FastAPI 0.104.1
- **Deployment:** Hugging Face Spaces (Docker)
- **Model Loading:** Lazy loading on first request
- **CORS:** Configured for foodvis.in + localhost
- **Endpoints:**
  - `GET /` - API info
  - `GET /health` - Health check
  - `POST /predict` - Image classification
  - `GET /docs` - Swagger documentation

### Frontend (React + Vercel)
- **Framework:** React 18.2.0 (Create React App)
- **Styling:** Tailwind CSS (CDN)
- **Deployment:** Vercel (automatic from GitHub)
- **Domain:** foodvis.in (via GoDaddy DNS)
- **Features:**
  - Drag-and-drop image upload
  - Real-time prediction display
  - Confidence bars with color coding
  - Inference time tracking
  - Responsive design (mobile-friendly)

### Deployment Guide

See [DEPLOYMENT.md](DEPLOYMENT.md) for complete instructions:
1. Deploy backend to HF Spaces with Git LFS
2. Deploy frontend to Vercel
3. Configure custom domain (foodvis.in)
4. Verify end-to-end flow

**Cost:** ~$1/month (domain only, HF Spaces + Vercel free tiers)

## Development Status

âœ… **Core Infrastructure Complete**

- âœ… Data download script (Food101 subset extraction)
- âœ… Training pipeline (baseline + improved configs)
- âœ… Model architecture (EfficientNetB2 with gradual unfreezing)
- âœ… EvalHarness (metrics, confusion, calibration, latency)
- âœ… FastAPI backend with CORS
- âœ… React frontend with Tailwind CSS
- âœ… Deployment configs (HF Spaces + Vercel)
- â³ **Training runs** (run scripts above to train models)
- â³ **Production deployment** (follow DEPLOYMENT.md)

## Next Steps

1. **Train Models**
   ```bash
   python scripts/download_data.py
   python src/train.py --config configs/baseline.yaml
   python src/train.py --config configs/improved.yaml
   ```

2. **Evaluate Results**
   ```bash
   python scripts/evaluate.py --model artifacts/improved/best_model.pth
   ```

3. **Deploy Backend**
   - Copy model to `backend/models/`
   - Push to HF Spaces with Git LFS
   - Test API endpoint

4. **Deploy Frontend**
   - Push to GitHub
   - Import to Vercel
   - Configure domain (foodvis.in)

## What Would Change My Mind

**Current hypothesis:** EfficientNetB2 frozen backbone + linear head can achieve >90% accuracy on 3-class Food101 subset.

**What would invalidate this:**
- Accuracy <85% after proper hyperparameter tuning
- Latency >200ms p95 on CPU (making it impractical for real-time use)
- Robustness degradation >20% under mild corruption
- Failure to generalize to similar food images outside Food101

## License

MIT

---

**Part of the 2026 ML/AI Engineering Portfolio**
End-to-end image classification with honest evaluation and deployment.
